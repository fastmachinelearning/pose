{
    "title": "Success Stories",
    "subtitle": "Utilizing the Power of hls4ml for Transformative Applications in Embedded Systems and Material Science.",
    "stories": [
        {
            "title": "Instantaneous Phase Estimation in Neuroscience",
            "subtitle": "Real-Time Brain-Computer Interface Using hls4ml in SpikeGadgets",
            "image": "/img/istantaneous-phase-estimation.png",
            "imageAttribution": "",
            "content": [
                {
                    "title": "Background",
                    "text": "Electroencephalography (EEG) and Local Field Potential (LFP) recordings capture brain activity through oscillating wave patterns at various frequencies. Estimating the phase of these signals is crucial for understanding how the brain functions and is essential for technologies like brain-computer interfaces (BCIs) and neurofeedback systems."
                },
                {
                    "title": "Strategy",
                    "text": "We introduce DCTNN, a machine learning model that splits signals into real and imaginary parts to improve real-time phase estimation. We also explore how combining machine learning with frequency methods like Fast Fourier Transform (FFT) enhances phase extraction from EEG and LFP signals. Using hls4ml, we convert these models into formats that run efficiently on FPGAs. This integration allows the models to process neurological data directly on the data acquisition platform, enabling fast and accurate phase estimation."
                },
                {
                    "title": "Results",
                    "text": "The Phase Estimation model developed in this project significantly outperforms traditional Fast Fourier Transform (FFT) and ecHT models. We successfully integrated a simple machine learning model into the SpikeGadgets platform. This research demonstrates that our method allows for more accurate real-time analysis of brain activity and behavior by extracting phase information from rodent brain signals."
                }
            ]
        },
        {
            "title": "In-Situ High-Speed Computer Vision",
            "subtitle": "Deploying neural networks for in-situ inference on frame grabber FPGAs in high-speed imaging <br><br><a href='https://medium.com/@forelliryan/deploying-neural-networks-for-in-situ-inference-on-frame-grabber-fpgas-in-high-speed-imaging-6201557fdabc'><u>Medium article</u></a><br><a href='https://arxiv.org/abs/2312.00128'><u>Fusion Paper</u></a>",
            "image": "/img/in-situ-computer-vision.png",
            "imageAttribution": "Daisuke Shiraki",
            "content": [
                {
                    "title": "Background",
                    "text": "Many scientific domains utilize high-speed imaging to aid in experimentation and discovery. From analyzing fusion magneto hydrodynamics, to crystal structure detection in transmission electron microscopy, there is a need for in-situ fast inference in these experiments which operate in the kHz to MHz range."
                },
                {
                    "title": "Strategy",
                    "text": "Typically, dedicated PCIe frame grabber devices are paired with high-speed cameras to handle such high throughput, and a protocol such as CoaXPress is used to transmit the raw camera data between the systems. Many frame grabbers implement this protocol as well as additional pixel preprocessing stages on an FPGA device, for which the manufacturer makes the reference design available. Moreover, open-source codesign workflows like hls4ml enable easy translation and deployment of neural networks to FPGA devices, and have demonstrated latencies on the order of nanoseconds to microseconds. We leverage these existing tools to construct a framework for quick neural network deployment to frame grabber FPGAs."
                },
                {
                    "title": "Results",
                    "text": "We construct a framework for easy deployment of hls4ml neural networks to the frame grabbers for use in real-time control, data reduction, manufacturing, or other applications. The framework comes complete with two comprehensive tutorials, C/RTL testbenches, and pre-written HDL to enable easy inference latency benchmarking. We have successfully applied this framework to the field of fusion magnetohydrodynamics with more applications in progress."
                }
            ]
        },
        {
            "title": "Wildfire Project",
            "subtitle": "Enabling Embedded Systems and IoT with hls4ml",
            "image": "/img/project-wildfire.png",
            "content": [
                {
                    "title": "Background",
                    "text": "Wildfires pose an increasingly urgent global threat, as evidenced by recent devastating events in Maui, Hawaii, and across Alaska. To address this challenge, robust and reliable AI-based wildfire detection models are imperative. Our ongoing research has yielded significant advancements in video and image-based wildfire detection and ember detection AI models aimed at early prevention efforts."
                },
                {
                    "title": "Strategy",
                    "text": "Recognizing the computational demands of these models, we propose leveraging Field Programmable Gate Arrays (FPGAs) due to their proven flexibility and parallel computation advantages. FPGAs serve as efficient hardware accelerators for deploying deep learning models, ensuring timely and accurate wildfire detection."
                },
                {
                    "title": "Results",
                    "text": "To facilitate the integration of our AI detection models onto FPGAs, which have been trained using various frameworks including PyTorch and TensorFlow-Keras, we rely on the pivotal role of hls4ml in implementation. Our project focuses on demonstrating the effectiveness of AI models on FPGAs through the utilization of hls4ml, thereby enabling rapid and efficient wildfire detection and prevention strategies."
                }
            ]
        },
        {
            "title": "High Speed Camera+4D TEM",
            "subtitle": "Enabling Material Science with hls4ml",
            "image": "/img/4d_tem_jca.png",
            "imageAttribution": "Joshua Agar",
            "content": [
                {
                    "title": "Background",
                    "text": "4D Scanning Transmission Electron Microscopy (4D-STEM) is a powerful technique for atomic resolution imaging. One common imaging mode captures 2D diffraction images at each pixel position in real space. The direct electron detectors used can reach 4K resolution at frame rates up to 5000 frames-per-second. This has led to orders of magnitude increase in the volume and velocity of the data collected, creating challenges in how to efficiently extract actionable information."
                },
                {
                    "title": "Strategy",
                    "text": "We propose and demonstrate a machine learning hardware implementation for real-time crystal structure, rotation, and strain detection in 4D-STEM by leveraging a novel deep neural network (DNN) called a cycle-consistent spatial-transforming autoencoder (CC-ST-AE) capable of learning affine transformations on real and simulation data. We then use distillation to train a smaller, quantized, easily-deployable version of the model to enable real-time inference and high throughput."
                },
                {
                    "title": "Results",
                    "text": "We use hls4ml to synthesize the distilled model and optimize the implementation to meet the required latency constraint of 100us. We then integrate the neural network in the readout path of the imaging system onboard a Euresys CoaXPress frame grabber to minimize IO-related overhead. This work provides a proof-of-concept for real-time crystal structure detection in 4D-STEM, significantly increasing the potential for fast materials characterization and discovery."
                }
            ]
        }
    ]
}